# ğŸ¤– Web Summarizer - AI Chrome Extension

A privacy-focused Chrome extension that uses locally-hosted AI (Qwen3) to instantly summarize web pages. No cloud APIs, no data sharing - everything runs on your machine.

<img width="1919" height="807" alt="image" src="https://github.com/user-attachments/assets/f65e605e-1e67-44ea-aed4-e55ecb5293d9" />

## âœ¨ Features

- ğŸ”’ **100% Privacy** - All processing happens locally
- âš¡ **Real-time Streaming** - Watch summaries generate live
- ğŸ¯ **Smart AI** - Powered by Qwen3 1.7B via Ollama
- ğŸš€ **Fast** - Summaries in 3-5 seconds
- ğŸ’¾ **Lightweight** - Only 1.4GB model size

## ğŸ“‹ Prerequisites

- Python 3.10+
- Google Chrome
- [Ollama](https://ollama.ai/download)

## ğŸš€ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/yourusername/web-summarizer.git
cd web-summarizer
```

### 2. Install Ollama & Pull Model
```bash
# Install Ollama from https://ollama.ai/download
# Then pull the model:
ollama pull qwen3:1.7b
```

### 3. Setup Backend
```bash
cd backend

# Create virtual environment (optional but recommended)
python -m venv venv
source venv/Scripts/activate  # Windows Git Bash
# OR: venv\Scripts\activate.bat  # Windows CMD
# OR: source venv/bin/activate   # macOS/Linux

# Install dependencies
pip install -r requirements.txt

# Start the server
uvicorn app:app --host 0.0.0.0 --port 7864
```

### 4. Install Chrome Extension
1. Open Chrome â†’ `chrome://extensions/`
2. Enable **Developer mode** (top-right toggle)
3. Click **Load unpacked**
4. Select the `extension` folder
5. Extension icon appears in toolbar âœ…

### 5. Use It!
1. Visit any webpage
2. Click the extension icon
3. Click "Summarize This Page"
4. Get instant AI summary! ğŸ‰

## ğŸ“ Project Structure
```
web-summarizer/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # FastAPI server
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ Dockerfile          # Optional Docker setup
â””â”€â”€ extension/
    â”œâ”€â”€ manifest.json       # Extension config
    â”œâ”€â”€ popup.html          # UI interface
    â”œâ”€â”€ popup.js            # Frontend logic
    â”œâ”€â”€ content.js          # Content extraction
    â”œâ”€â”€ background.js       # Background worker
    â””â”€â”€ icon.png            # Extension icon
```

## ğŸ”§ Troubleshooting

**Backend won't start:**
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Verify model is installed
ollama list
```

**Content too long error:**
- Normal! Content is automatically truncated
- Or use larger model: `ollama pull qwen3:8b`

**Extension not working:**
- Ensure backend is running on port 7864
- Check `chrome://extensions/` for errors
- Reload the extension after changes

## âš™ï¸ Configuration

Change model in `backend/app.py`:
```python
bot = Assistant(
    llm={
        "model": "qwen3:1.7b",  # Options: qwen3:0.6b, qwen3:4b, qwen3:8b
        # ...
    }
)
```

## ğŸ¯ Tech Stack

- **Backend:** Python, FastAPI, Qwen-Agent
- **AI Model:** Qwen3 1.7B (via Ollama)
- **Frontend:** JavaScript, Chrome Extensions API
- **Deployment:** Local inference, no cloud required

## ğŸ“Š Performance

| Metric | Value |
|--------|-------|
| Model Size | 1.4 GB |
| Processing Time | 3-7 seconds |
| Context Limit | ~3,500 tokens |
| RAM Usage | 2-4 GB |

## ğŸ“ License

MIT License - feel free to use and modify!

## ğŸ™ Acknowledgments

- [Ollama](https://ollama.ai/) - Local LLM deployment
- [Qwen Team](https://github.com/QwenLM/Qwen) - Open-source language models
- [FastAPI](https://fastapi.tiangolo.com/) - Web framework

---

**Made with â¤ï¸ | Star â­ if you find this useful!**
